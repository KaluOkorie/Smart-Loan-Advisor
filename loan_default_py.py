# -*- coding: utf-8 -*-
"""Loan_default.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZU9Xv20fjQaJ8cfYk8HahbvUwPezMZKa
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

from pandas.core.indexes.api import Index
data=pd.read_csv('loan_approval_dataset.csv')
data.head()

data.info()

data.columns

"""## Begin data cleaning and Exploration"""

Loan_df = data.copy()
Loan_df.columns = Loan_df.columns.str.strip()

Loan_df.columns

Loan_df = Loan_df.rename(columns={'cibil_score': 'credit_score'})

Loan_df.drop('loan_id',axis=1,inplace=True)

Loan_df.tail(10)

Loan_df.shape

Loan_df.describe()

Loan_df[Loan_df['residential_assets_value'] < 0]

len(Loan_df[Loan_df['residential_assets_value'] < 0])

"""## convert negative to nan and to median"""

col = 'residential_assets_value'

# Replace negatives with NaN
Loan_df.loc[Loan_df[col] < 0, col] = np.nan

# Fill NaN with median
Loan_df[col].fillna(Loan_df[col].median(), inplace=True)

Loan_df[Loan_df['residential_assets_value'] < 0]

Loan_df.describe(include='object')

Loan_df.isna().sum()

"""## cleaning the target column"""

Loan_df['loan_status'].unique()

Loan_df['loan_status'] = Loan_df['loan_status'].str.strip().str.lower()

Loan_df['loan_status'].unique()

Loan_df['loan_status'] = Loan_df['loan_status'].map({
    'approved': 1,
    'rejected': 0
})

Loan_df['loan_status'].isna().sum()

sns.countplot(x= 'loan_status', data=Loan_df)
plt.title("loan_status Class Distribution")
plt.show()

sns.pairplot(Loan_df, hue='loan_status')

plt.figure(figsize=(10,6))
sns.heatmap(Loan_df.corr(numeric_only=True), annot=True, cmap='coolwarm')
plt.show()

"""## Models for ML"""

# Core ML utilities
from sklearn.model_selection import train_test_split

# Classification models
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score,)

# XGBoost (external library)
import xgboost as xgb
from xgboost import XGBClassifier

# Encoding
from sklearn.preprocessing import OneHotEncoder

# Evaluation metrics
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Separate features and target
y = Loan_df["loan_status"]
X = Loan_df.drop("loan_status", axis=1)

#  Encode categorical features
X = pd.get_dummies(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

#confirm shape is alinged
X_train.shape, X_test.shape, y_train.shape, y_test.shape

# Define your models
models = {
    "Random Forest": RandomForestClassifier(),
    "Decision Tree": DecisionTreeClassifier(),
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "SVM": SVC(probability=True),
    "Gradient Boosting": GradientBoostingClassifier(),
    "XGBoost": XGBClassifier(eval_metric='logloss')
}

# Evaluate all models
results = {}

for name, model in models.items():
    model.fit(X_train, y_train)                 # train the model
    y_pred = model.predict(X_test)              # class predictions
    y_prob = model.predict_proba(X_test)[:, 1]  # probability predictions for ROC-AUC

    # Classification metrics
    acc = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, zero_division=0)
    recall = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)
    roc = roc_auc_score(y_test, y_prob)

    # store metrics for this model
    results[name] = {
        "Accuracy": acc,
        "Precision": precision,
        "Recall": recall,
        "F1-score": f1,
        "ROC-AUC": roc
    }

# Convert results dictionary â†’ DataFrame
results_df = pd.DataFrame(results).T

# Sort models by Accuracy (descending)
results_df = results_df.sort_values(by="Accuracy", ascending=False)

# Display the formatted results
results_df

"""## Tunning the best 2 Models"""

from sklearn.model_selection import RandomizedSearchCV

rf_params = {
    "n_estimators": [200, 300, 500, 800],
    "max_depth": [None, 10, 20, 30],
    "min_samples_split": [2, 5, 10],
    "min_samples_leaf": [1, 2, 4],
    "bootstrap": [True, False]
}

rf_model = RandomForestClassifier()

rf_search = RandomizedSearchCV(
    estimator=rf_model,
    param_distributions=rf_params,
    n_iter=20,
    cv=5,
    scoring="accuracy",
    n_jobs=-1,
    random_state=42
)

rf_search.fit(X_train, y_train)
best_rf = rf_search.best_estimator_

from xgboost import XGBClassifier

xgb_params = {
    "n_estimators": [200, 300, 500],
    "learning_rate": [0.01, 0.05, 0.1],
    "max_depth": [3, 5, 7],
    "subsample": [0.7, 0.8, 1.0],
    "colsample_bytree": [0.7, 0.8, 1.0],
    "gamma": [0, 0.1, 0.2],
}

xgb_model = XGBClassifier(eval_metric="logloss")

xgb_search = RandomizedSearchCV(
    estimator=xgb_model,
    param_distributions=xgb_params,
    n_iter=20,
    cv=5,
    scoring="accuracy",
    n_jobs=-1,
    random_state=42
)

xgb_search.fit(X_train, y_train)
best_xgb = xgb_search.best_estimator_

from sklearn.metrics import accuracy_score, classification_report

models = {
    "Random Forest (Tuned)": best_rf,
    "XGBoost (Tuned)": best_xgb
}

results = {}

for name, model in models.items():
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    results[name] = acc

results

"""## Accuracy alone can be misleading"""

import pandas as pd
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, roc_auc_score
)

comparison = []

for name, model in models.items():
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)[:, 1]

    comparison.append({
        "Model": name,
        "Accuracy": accuracy_score(y_test, y_pred),
        "Precision": precision_score(y_test, y_pred, pos_label=1),
        "Recall": recall_score(y_test, y_pred, pos_label=1),
        "F1 Score": f1_score(y_test, y_pred, pos_label=1),
        "ROC-AUC": roc_auc_score(y_test, y_proba)
    })

comparison_df = pd.DataFrame(comparison)
comparison_df

"""MODEL PERFORMANCE SUMMARY

Accuracy (97.9%):
The model makes the correct decision about 98 times out of 100.

Precision (97.9%):
When the model approves a loan, about 98 out of 100 approvals are correct.

Recall (98.7%):
Out of every 100 people who truly deserve a loan, about 99 are approved.

F1 Score (0.983):
Shows a strong balance between being careful and not rejecting good customers.

ROC-AUC (0.998):
The model is excellent at separating good applicants from bad ones.

Overall conclusion:
The model is accurate, fair, reliable, and well-balanced.
"""

rf_importance = pd.DataFrame({
    "Feature": X_train.columns,
    "Importance": best_rf.feature_importances_
}).sort_values(by="Importance", ascending=False)

rf_importance

xgb_importance = pd.DataFrame({
    "Feature": X_train.columns,
    "Importance": best_xgb.feature_importances_
}).sort_values(by="Importance", ascending=False)
xgb_importance

"""## Save best trained model"""

import joblib

# Save the best-performing model
best_model = best_xgb   # XGBoost (Tuned)

# Save feature names (very important for inference)
feature_columns = X_train.columns.tolist()

joblib.dump(best_model, "best_xgb_model.pkl")
joblib.dump(feature_columns, "feature_columns.pkl")

